{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ed845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_train = os.path.join('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fec70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(dataset_dir_train, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(dataset_dir_train)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.convnext_base(pretrained=True)\n",
    "model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ffb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loaders for training, validation, and testing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac941d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, device):\n",
    "    model.eval()\n",
    "    class_results = {cls: {'correct': [], 'incorrect': [], 'features': []} for cls in class_names}\n",
    "    all_features = {cls: [] for cls in class_names}\n",
    "\n",
    "    def extract_features(model, x):\n",
    "        x = model.features(x)\n",
    "        return nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(train_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            features = extract_features(model, images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            _, predicted = torch.max(probabilities, dim=1)\n",
    "            _, top5_indices = torch.topk(probabilities, k=3, dim=1)\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                true_class = class_names[label.item()]\n",
    "                pred_class = class_names[predicted[i].item()]\n",
    "\n",
    "                class_results[true_class]['correct'].append(predicted[i] == label)\n",
    "                class_results[true_class]['features'].append(features[i].cpu())\n",
    "\n",
    "                if predicted[i] == label:\n",
    "                    incorrect_classes = [class_names[idx.item()] for idx in top5_indices[i, 1:]]\n",
    "\n",
    "                    incorrect_features = []\n",
    "                    for cls in incorrect_classes:\n",
    "                        incorrect_features.extend(all_features[cls])\n",
    "\n",
    "                    if incorrect_features:\n",
    "                        target_vector = torch.stack(incorrect_features).mean(0)\n",
    "                        class_results[true_class]['target_vector'] = target_vector\n",
    "                else:\n",
    "                    class_results[true_class]['incorrect'].append(features[i].cpu())\n",
    "\n",
    "                all_features[true_class].append(features[i].cpu())\n",
    "\n",
    "    target_feature_vectors = {}\n",
    "    for cls in class_names:\n",
    "        accuracy = sum(class_results[cls]['correct']) / len(class_results[cls]['correct'])\n",
    "\n",
    "        correct_features = [f for f, c in zip(class_results[cls]['features'], class_results[cls]['correct']) if c]\n",
    "        if correct_features:\n",
    "            target_vector = torch.stack(correct_features).mean(0)\n",
    "            target_feature_vectors[cls] = target_vector\n",
    "\n",
    "        for i, feature in enumerate(class_results[cls]['incorrect']):\n",
    "            class_results[cls]['incorrect'][i] = target_feature_vectors[cls]\n",
    "\n",
    "    return target_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vectors = evaluate_model(model, train_loader, device)\n",
    "\n",
    "# Save target feature vectors\n",
    "torch.save(target_vectors, '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
